# ============================================================
# Stage 1: Builder（CUDA 12.8 devel：编译 FA2 + 尝试装 xformers）
# ============================================================
FROM nvidia/cuda:12.8.1-cudnn-devel-ubuntu24.04 AS builder

MAINTAINER Rabin "https://github.com/shemic"
ENV DEBIAN_FRONTEND=noninteractive
WORKDIR /opt

# CA 证书
RUN apt update && apt install -y ca-certificates && update-ca-certificates

# 国内 APT 源（deb822）
RUN mkdir -p /etc/apt/sources.list.d && \
    printf "Types: deb\nURIs: https://mirrors.ustc.edu.cn/ubuntu/\nSuites: noble noble-updates noble-backports noble-security\nComponents: main restricted universe multiverse\nSigned-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg\n" \
    > /etc/apt/sources.list.d/ubuntu.sources

# 编译链 + Python dev（FA2 需要 nvcc）
RUN apt update && apt install -y \
    bash \
    python3 python3-venv python3-pip python3-dev \
    git curl wget \
    build-essential ninja-build \
    && rm -rf /var/lib/apt/lists/*

# pip 国内源 + 关闭 PEP668
RUN pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple && \
    rm -f /usr/lib/python3.12/EXTERNALLY-MANAGED && \
    pip3 config set global.break-system-packages true

# 安装 PyTorch cu128（三件套对齐）
RUN pip3 install --no-cache-dir \
  torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
  --index-url https://download.pytorch.org/whl/cu128

# ============================================================
# 安装 FlashAttention2（源码编译）
# 这里编译成“多架构 fat binary”，一个镜像多卡通用：
#   sm80：A100/A800
#   sm86：30 系大多数卡、A10 等
#   sm89：40 系（4090/4080）
#   sm90：H20/H100/H800
# ============================================================
ENV FLASH_ATTN_CUDA_ARCHS="80;86;89;90"
ENV MAX_JOBS=8
RUN pip3 install --no-cache-dir packaging && \
    pip3 install --no-cache-dir flash-attn --no-build-isolation

# 尝试安装 xformers（如果没有对应 wheel/编译失败，不让构建中断）
# 注意：xformers 在 PyPI，不在 pytorch cu128 仓库
RUN pip3 install --no-cache-dir --prefer-binary xformers \
    --extra-index-url https://download.pytorch.org/whl/cu128 \
    || echo "xformers wheel/build not available for this combo, fallback to FA2/SDPA"

# 拉 ComfyUI
RUN git clone https://github.com/comfyanonymous/ComfyUI.git /opt/ComfyUI
WORKDIR /opt/ComfyUI

# 安装 ComfyUI requirements（加 cu128 额外源，避免 torch 被 CPU 覆盖）
RUN pip3 install --no-cache-dir -r requirements.txt \
    --extra-index-url https://download.pytorch.org/whl/cu128


# ============================================================
# Stage 2: Runtime（你要求：纯 ubuntu:24.04）
# ============================================================
FROM ubuntu:24.04

MAINTAINER Rabin "https://github.com/shemic"
ENV DEBIAN_FRONTEND=noninteractive
WORKDIR /opt

# CA 证书
RUN apt update && apt install -y ca-certificates && update-ca-certificates

# 国内源
RUN mkdir -p /etc/apt/sources.list.d && \
    printf "Types: deb\nURIs: https://mirrors.ustc.edu.cn/ubuntu/\nSuites: noble noble-updates noble-backports noble-security\nComponents: main restricted universe multiverse\nSigned-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg\n" \
    > /etc/apt/sources.list.d/ubuntu.sources

# 运行层只装运行必需
RUN apt update && apt install -y \
    bash \
    python3 python3-venv python3-pip \
    git curl wget \
    libgl1 libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# pip 国内源 + 关闭 PEP668
RUN pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple && \
    rm -f /usr/lib/python3.12/EXTERNALLY-MANAGED && \
    pip3 config set global.break-system-packages true

# 拷贝 builder 的 torch + FA2 + xformers（如果 builder 装成功）+ comfyui
COPY --from=builder /usr/local/lib/python3.12/dist-packages /usr/local/lib/python3.12/dist-packages
COPY --from=builder /usr/local/bin /usr/local/bin
COPY --from=builder /opt/ComfyUI /opt/ComfyUI

WORKDIR /opt/ComfyUI

# 运行期优化（通用）
ENV PYTORCH_ALLOC_CONF=expandable_segments:True,max_split_size_mb:256
ENV CUDA_MODULE_LOADING=LAZY
ENV TORCH_LOGS=off

# 全局 TF32 + cudnn benchmark（推理免费提速）
RUN python3 - <<'PY'
import site, os
p = site.getsitepackages()[0]
sc = os.path.join(p, 'sitecustomize.py')
with open(sc, 'w') as f:
    f.write('import torch\n')
    f.write('torch.backends.cuda.matmul.allow_tf32 = True\n')
    f.write('torch.backends.cudnn.allow_tf32 = True\n')
    f.write('torch.backends.cudnn.benchmark = True\n')
print('written', sc)
PY

EXPOSE 8188
SHELL ["/bin/bash", "-c"]

# 默认强制用 FA2（你要用 xformers 时改成 --use-xformers）
CMD ["python3", "main.py", "--listen", "0.0.0.0", "--port", "8188", "--use-flash-attention"]
